{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Carga de paquetes (y en el colab meter la imagen, habrá que quitar lo del google colab)"
      ],
      "metadata": {
        "id": "Xf95CSsw6Q-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5b31cTtepbb"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install easyocr\n",
        "\n",
        "import cv2\n",
        "import easyocr\n",
        "import pytesseract\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "reader = easyocr.Reader(['hi','en'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ocr pytesseract para detectar texto directamente (pocho):"
      ],
      "metadata": {
        "id": "8QOKTRpc6hmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_in_colab=\"/content/WhatsApp Image 2023-11-04 at 12.02.57 (1).jpeg\"\n",
        "\n",
        "extractedInformation = pytesseract.image_to_string(Image.open(image_path_in_colab))\n",
        "print(pytesseract.image_to_boxes(Image.open(image_path_in_colab)))\n",
        "print(extractedInformation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoNl6Q1De-TG",
        "outputId": "a5e0cc85-8e68-4e63-85b2-d78b3a455bc0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H 126 1703 152 1763 0\n",
            "E 157 1713 179 1754 0\n",
            "L 190 1715 206 1755 0\n",
            "L 213 1713 224 1754 0\n",
            "O 237 1716 265 1750 0\n",
            ". 258 1703 265 1763 0\n",
            "M 345 1721 373 1761 0\n",
            "Y 382 1721 405 1757 0\n",
            "W 453 1721 479 1763 0\n",
            "A 453 1721 497 1762 0\n",
            "H 498 1725 539 1763 0\n",
            "1 578 1731 599 1763 0\n",
            "5 602 1726 644 1797 0\n",
            "~ 0 0 853 1861 0\n",
            "\n",
            "HELLO. MY WAH 15\n",
            "\n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ocr easyocr para detectar texto directamente (mejor):"
      ],
      "metadata": {
        "id": "t4SE-34Q6jaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bounds = reader.readtext(image_path_in_colab, detail=0) #detail=0 argument will only give text in array\n",
        "print(\"Output:\")\n",
        "print(bounds)"
      ],
      "metadata": {
        "id": "Lng5ha2_AyoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ocr pytesseract para sacar imagenes letra a letra:"
      ],
      "metadata": {
        "id": "WZkuQOQ96uOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(image_path_in_colab)\n",
        "\n",
        "# Convertir a escala de grises\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Aplicar umbralización o técnicas de binarización si es necesario\n",
        "\n",
        "# Aplicar un filtro de suavizado o técnicas de eliminación de ruido si es necesario\n",
        "\n",
        "# Detección de bordes con el algoritmo Canny\n",
        "edged_image = cv2.Canny(gray, threshold1=30, threshold2=100)  # Ajusta los valores de umbral según tu imagen\n",
        "\n",
        "# Encuentra los contornos en la imagen de bordes\n",
        "contours, _ = cv2.findContours(edged_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Recorrer los contornos identificados\n",
        "for contour in contours:\n",
        "    # Obtener las coordenadas y dimensiones de cada contorno\n",
        "    x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "    # Recortar la región con la letra\n",
        "    letter_region = image[y:y+h, x:x+w]\n",
        "\n",
        "    # Aplicar OCR para reconocimiento de texto en la región\n",
        "    text = pytesseract.image_to_string(letter_region, lang='eng')\n",
        "\n",
        "    # Guardar la imagen de la letra y el texto reconocido\n",
        "    cv2.imwrite('letra_{}.png'.format(text), letter_region)"
      ],
      "metadata": {
        "id": "dtWaIx5k14Dx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ocr easyocr para sacar imagenes letra a letra:"
      ],
      "metadata": {
        "id": "zVYjaqwe60vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir a escala de grises\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Aplicar umbralización o técnicas de binarización si es necesario\n",
        "\n",
        "# Aplicar un filtro de suavizado o técnicas de eliminación de ruido si es necesario\n",
        "\n",
        "# Configurar EasyOCR\n",
        "reader = easyocr.Reader(['en'])  # Puedes añadir más idiomas si es necesario\n",
        "\n",
        "# Encontrar contornos en la imagen de bordes\n",
        "contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Recorrer los contornos identificados\n",
        "for contour in contours:\n",
        "    # Obtener las coordenadas y dimensiones de cada contorno\n",
        "    x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "    # Recortar la región con la letra\n",
        "    letter_region = image[y:y+h, x:x+w]\n",
        "\n",
        "    # Convertir la región a RGB (EasyOCR espera imágenes en formato RGB)\n",
        "    letter_rgb = cv2.cvtColor(letter_region, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Aplicar EasyOCR para reconocimiento de texto en la región\n",
        "    result = reader.readtext(letter_rgb)\n",
        "\n",
        "    if result:\n",
        "        text = result[0][-2]  # Tomar el texto reconocido\n",
        "\n",
        "        # Guardar la imagen de la letra y el texto reconocido\n",
        "        cv2.imwrite('letra_{}.png'.format(text), letter_region)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tSRBNDt68u5",
        "outputId": "9c8f6085-0a3e-46fa-b4c0-9d7cf615373b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ]
    }
  ]
}